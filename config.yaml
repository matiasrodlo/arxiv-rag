# RAG System Configuration

# Paths
paths:
  pdf_dir: "pdfs"
  metadata_dir: "pdfs"
  output_dir: "data/processed"
  vector_db_path: "data/vector_db"
  extracted_text_dir: "data/extracted_text"

# PDF Extraction
pdf_extraction:
  primary_library: "pymupdf"  # pymupdf, pdfplumber, pypdf
  enable_ocr: true
  ocr_language: "eng"
  min_text_length: 100  # Minimum characters to consider valid
  extract_metadata: true
  extract_references: true

# Text Processing
text_processing:
  remove_headers_footers: true
  normalize_whitespace: true
  fix_encoding: true
  improve_formulas: true  # Improve mathematical formula formatting
  min_chunk_size: 100  # Minimum characters per chunk
  max_chunk_size: 1000  # Maximum characters per chunk
  chunk_overlap: 200  # Overlap between chunks in characters
  preserve_sections: true

# Chunking
chunking:
  method: "semantic"  # semantic, fixed, sentence
  chunk_size: 512  # tokens
  chunk_overlap: 50  # tokens
  model: "sentence-transformers/all-MiniLM-L6-v2"  # For semantic chunking

# Embeddings
embeddings:
  model: "sentence-transformers/all-mpnet-base-v2"
  batch_size: 32
  device: "cpu"  # cpu, cuda, mps
  normalize_embeddings: true

# Vector Database
vector_db:
  type: "chroma"  # chroma, qdrant
  collection_name: "arxiv_cs_papers"
  persist_directory: "data/vector_db"
  # For Qdrant:
  # qdrant_host: "localhost"
  # qdrant_port: 6333

# Retrieval
retrieval:
  top_k: 10
  use_hybrid_search: true
  hybrid_alpha: 0.7  # Weight for semantic search (0.7) vs keyword (0.3)
  use_reranking: true
  rerank_top_k: 50  # Re-rank top 50, return top 10
  reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"

# Processing
processing:
  batch_size: 100  # Papers per batch
  num_workers: 4  # Parallel workers
  max_retries: 3
  retry_delay: 1  # seconds

# Logging
logging:
  level: "INFO"
  log_file: "logs/rag_pipeline.log"
  log_rotation: "100 MB"

